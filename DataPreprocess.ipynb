{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "First We need to Preprocess and Clean the data"
      ],
      "metadata": {
        "id": "8RhoBh5PzGIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Download NLTK data if needed\n",
        "nltk.download('punkt')\n",
        "\n",
        "class TextPreprocessor:\n",
        "    def __init__(self):\n",
        "        self.max_sentence_length = 0\n",
        "        self.labels_dict = {}  # Store labels mapping here\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        # Your text cleaning code here\n",
        "        text = text.lower()\n",
        "        text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=<>;]\", \" \", text)\n",
        "        text = re.sub(r\";\", \" \", text)\n",
        "        text = re.sub(r\",\", \" \", text)\n",
        "        text = re.sub(r\"\\.\", \" \", text)\n",
        "        text = re.sub(r\"!\", \" ! \", text)\n",
        "        text = re.sub(r\"\\/\", \" \", text)\n",
        "        text = re.sub(r\"\\^\", \" ^ \", text)\n",
        "        text = re.sub(r\"\\+\", \" + \", text)\n",
        "        text = re.sub(r\"\\-\", \" - \", text)\n",
        "        text = re.sub(r\"\\=\", \" = \", text)\n",
        "        text = re.sub(r\"'\", \" \", text)\n",
        "        text = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "        text = re.sub(r\"\\'s\", \" \", text)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def load_data(self, path):\n",
        "        data = []\n",
        "        lines = [line.strip() for line in open(path)]\n",
        "\n",
        "        for idx in range(0, len(lines), 4):\n",
        "            id = lines[idx].split(\"\\t\")[0]\n",
        "            relation = lines[idx + 1]\n",
        "\n",
        "            sentence = lines[idx].split(\"\\t\")[1][1:-1]\n",
        "            sentence = sentence.replace('<e1>', ' _e11_ ')\n",
        "            sentence = sentence.replace('</e1>', ' _e12_ ')\n",
        "            sentence = sentence.replace('<e2>', ' _e21_ ')\n",
        "            sentence = sentence.replace('</e2>', ' _e22_ ')\n",
        "\n",
        "            sentence = self.clean_text(sentence)\n",
        "            tokens = nltk.word_tokenize(sentence)\n",
        "            if self.max_sentence_length < len(tokens):\n",
        "                self.max_sentence_length = len(tokens)\n",
        "            sentence = \" \".join(tokens)\n",
        "\n",
        "            data.append([id, sentence, relation])\n",
        "\n",
        "        df = pd.DataFrame(data=data, columns=[\"id\", \"sentence\", \"relation\"])\n",
        "\n",
        "        # Convert relation labels to numeric values\n",
        "        df['label'] = df['relation'].map(self.get_label_id)\n",
        "\n",
        "        # Text Data\n",
        "        x_text = df['sentence'].tolist()\n",
        "\n",
        "        # Label Data\n",
        "        y = df['label'].values\n",
        "\n",
        "        return x_text, y\n",
        "\n",
        "    def get_label_id(self, relation):\n",
        "        if relation not in self.labels_dict:\n",
        "            self.labels_dict[relation] = len(self.labels_dict)\n",
        "        return self.labels_dict[relation]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    preprocessor = TextPreprocessor()\n",
        "    trainFile = '/content/TRAIN_FILE.TXT'\n",
        "    testFile = '/content/TEST_FILE_FULL.TXT'\n",
        "\n",
        "    x_train, y_train = preprocessor.load_data(trainFile)\n",
        "    x_test, y_test = preprocessor.load_data(testFile)\n",
        "    # Now we have x_train, y_train, x_test, and y_test for further processing.\n",
        "    # Access and print the labels and their numeric IDs\n",
        "    #labels_dict = preprocessor.labels_dict\n",
        "    #for label, label_id in labels_dict.items():\n",
        "        #print(f\"{label},{label_id}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAG6F5m_zET3",
        "outputId": "1968bbc8-e9a1-4233-a8dc-6952b476d3f7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}